{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Crop characters from one image.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICnBWwRSzr0q"
      },
      "source": [
        "### https://medium.com/coinmonks/a-box-detection-algorithm-for-any-image-containing-boxes-756c15d7ed26"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDPvtw3Hzr0s"
      },
      "source": [
        "# Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsxU_CHpzr0u"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kf79aEFzr00"
      },
      "source": [
        "# Defining the table for Croping Characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6FDU9-Czr01"
      },
      "source": [
        "# Read the image\n",
        "img = cv2.imread(\"A.jpeg\", 0)\n",
        "\n",
        "# Thresholding the image\n",
        "(thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "# Invert the image\n",
        "img_bin = 255-img_bin \n",
        "#cv2.imwrite(\"Image_bin.jpg\",img_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czLfUhbtzr09"
      },
      "source": [
        "# Defining a kernel length\n",
        "kernel_length = np.array(img).shape[1]//80\n",
        " \n",
        "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
        "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
        "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
        "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
        "# A kernel of (3 X 3) ones.\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aDnE16Izr1F"
      },
      "source": [
        "# Morphological operation to detect vertical lines from an image\n",
        "img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
        "verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
        "##cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
        "# Morphological operation to detect horizontal lines from an image\n",
        "img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
        "horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
        "##cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "599lEgDSzr1N"
      },
      "source": [
        "# Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
        "alpha = 0.5\n",
        "beta = 1.0 - alpha\n",
        "# This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
        "img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
        "img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
        "(thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "#cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j496lQmTzr1Y"
      },
      "source": [
        "# definig this code from https://www.pyimagesearch.com/2015/04/20/sorting-contours-using-python-and-opencv/\n",
        "def sort_contours(cnts, method=\"left-to-right\"):\n",
        "    # initialize the reverse flag and sort index\n",
        "    reverse = False\n",
        "    i = 0\n",
        "    # handle if we need to sort in reverse\n",
        "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
        "        reverse = True\n",
        "    # handle if we are sorting against the y-coordinate rather than\n",
        "    # the x-coordinate of the bounding box\n",
        "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
        "        i = 1\n",
        "    # construct the list of bounding boxes and sort them from top to\n",
        "    # bottom\n",
        "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "        key=lambda b:b[1][i], reverse=reverse))\n",
        "    # return the list of sorted contours and bounding boxes\n",
        "    return (cnts, boundingBoxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGm6QYCTzr1d"
      },
      "source": [
        "# Find contours for image, which will detect all the boxes\n",
        "contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "# Sort all the contours by top to bottom.\n",
        "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vMoaI1Xzr1k"
      },
      "source": [
        "# Croping the character and store into the croped folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfiIPztqzr1l"
      },
      "source": [
        "croped_dir_path = \"croped/cropA\"\n",
        "idx = 0\n",
        "oth = 0\n",
        "for c in contours:\n",
        "    # Returns the location and width,height for every contour\n",
        "    x, y, w, h = cv2.boundingRect(c)\n",
        "    if (290 > w > 270 and  150 > h > 140):\n",
        "        idx += 1\n",
        "        new_img = img[y:y+h, x:x+w]\n",
        "        cv2.imwrite(croped_dir_path+str(idx) + '.png', new_img)\n",
        "    else:\n",
        "        oth += 1\n",
        "        new_img = img[y:y+h, x:x+w]\n",
        "        cv2.imwrite(croped_dir_path+\"_not_used\"+str(oth) + '.png', new_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siuY9QGJzr1q"
      },
      "source": [
        "# Removing crop_not_used images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc-ec6pDzr1s",
        "outputId": "e620ac35-f8e6-4c13-8e85-fb6e56dbc78d"
      },
      "source": [
        "if input(\"Enter yes to remove unwaned files: \").lower() == \"yes\":\n",
        "    for i in os.listdir(\"croped\"):\n",
        "        if \"crop_not_used\" in i:\n",
        "            os.remove(\"croped/\"+i)\n",
        "            print(\"Removed File: \" + i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter yes to remove unwaned files: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yroIzCj6zr10"
      },
      "source": [
        "# Removing unwanted Space in croped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hl5ZIekzr11"
      },
      "source": [
        "for i in os.listdir(\"croped\"):\n",
        "    img = cv2.imread(\"croped/\"+i)\n",
        "    blurred = cv2.blur(img, (6,6))\n",
        "    canny = cv2.Canny(blurred, 50, 200)\n",
        "    ## find the non-zero min-max coords of canny\n",
        "    pts = np.argwhere(canny>0)\n",
        "    y1,x1 = pts.min(axis=0)\n",
        "    y2,x2 = pts.max(axis=0)\n",
        "    ## crop the region\n",
        "    cropped = img[y1:y2, x1:x2]\n",
        "    cv2.imwrite(\"croped/\"+i, cropped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SBX2sm2zr16"
      },
      "source": [
        "# Crop Specific image if needed ->> press C to crop  press esc to exit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBLEVxXqzr18"
      },
      "source": [
        "img_path = 'croped/crop29.png'\n",
        "image = cv2.imread(img_path)\n",
        "image_to_show = np.copy(image)\n",
        "mouse_pressed = False\n",
        "s_x = s_y = e_x = e_y = -1\n",
        "def mouse_callback(event, x, y, flags, param):\n",
        "    global image_to_show, s_x, s_y, e_x, e_y, mouse_pressed\n",
        "    if event == cv2.EVENT_LBUTTONDOWN:\n",
        "        mouse_pressed = True\n",
        "        s_x, s_y = x, y\n",
        "        image_to_show = np.copy(image)\n",
        "    elif event == cv2.EVENT_MOUSEMOVE:\n",
        "        if mouse_pressed:\n",
        "            image_to_show = np.copy(image)\n",
        "            cv2.rectangle(image_to_show, (s_x, s_y),(x, y), (0, 255, 0), 1)\n",
        "    elif event == cv2.EVENT_LBUTTONUP:\n",
        "        mouse_pressed = False\n",
        "        e_x, e_y = x, y\n",
        "cv2.namedWindow('image')\n",
        "cv2.setMouseCallback('image', mouse_callback)\n",
        "while True:\n",
        "    cv2.imshow('image', image_to_show)\n",
        "    k = cv2.waitKey(1)\n",
        "    if k == ord('c'):\n",
        "        if s_y > e_y:s_y, e_y = e_y, s_y\n",
        "        if s_x > e_x:s_x, e_x = e_x, s_x\n",
        "        if e_y - s_y > 1 and e_x - s_x > 0:\n",
        "            image = image[s_y:e_y, s_x:e_x]\n",
        "            image_to_show = np.copy(image)\n",
        "    elif k == 27:break\n",
        "cv2.destroyAllWindows()\n",
        "cv2.imwrite(img_path,image_to_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5H-wugOzr2B"
      },
      "source": [
        "# Image conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcsvDLgezr2C"
      },
      "source": [
        "a = cv2.imread(\"croped/crop1.png\")\n",
        "a_gray = cv2.cvtColor(a, cv2.COLOR_BGR2)\n",
        "a_blur = cv2.blur(a_gray, (15,15))\n",
        "plt.imshow(a_gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPw6n6sazr2G"
      },
      "source": [
        "# Characters Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU6fjQlVzr2H"
      },
      "source": [
        "img_rgb = cv2.imread(\"handwritten Characters/Preyash/1.jpg\")\n",
        "img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
        "img_blur = cv2.blur(img_gray, (15,15))\n",
        "for i in os.listdir(\"croped\"):\n",
        "    template = cv2.imread(\"croped/\"+i,0)\n",
        "    w, h = template.shape[::-1]\n",
        "    res = cv2.matchTemplate(img_blur,template,cv2.TM_CCOEFF_NORMED)\n",
        "    threshold = 0.8\n",
        "    loc = np.where( res >= threshold)\n",
        "    for pt in zip(*loc[::-1]):\n",
        "        cv2.rectangle(img_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n",
        "        cv2.putText(img_rgb, i, (pt[0] + w, pt[1] + h),cv2.FONT_HERSHEY_SIMPLEX , 1,(255,0,0))\n",
        "cv2.imwrite('output.png',img_rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zAhP-rgzr2M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}